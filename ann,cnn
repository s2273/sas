1)ANN
#Importing the necessary libraries
import pandas as pd
import numpy as np
from sklearn.datasets import make_classification, make_regression
import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
import sklearn
dir(sklearn.datasets)
#Importing the dataset
data = make_classification(200,4,random_state=1)
data
x = data[0]
y = data[1]
#Model Creation
model = Sequential()
model.add(Dense(1135, activation=&#39;tanh&#39;, input_dim=4))
model.add(Dense(624, activation=&#39;relu&#39;))
model.add(Dense(114, activation=&#39;relu&#39;))
model.add(Dense(1,activation=&#39;sigmoid&#39;))
adam = Adam(0.001)
#Model compilation
model.compile(optimizer=adam, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])
print(model.summary())
history = model.fit(x, y, epochs=150, batch_size=5, validation_split=0.2)
pd.DataFrame(model.history.history).reset_index().plot(&#39;index&#39;, kind=&#39;line&#39;)
data = pd.DataFrame(history.history)
data.loc[data[&#39;accuracy&#39;].idxmax()]
Regression:
#Importing the dataset
data = make_regression(200,4,random_state=1)
x=data[0]
y=data[1]
#r2
from keras import backend as k
def r2(y_true,y_pred):
ss_res = k.sum(k.square(y_true-y_pred))
ss_tot = k.sum(k.square(y_true-k.mean(y_true)))
return (1-ss_res/(ss_tot))
#Model Creation
model = Sequential()
model.add(Dense(1135,activation= &#39;tanh&#39;, input_dim = 4))
model.add(Dense(624, activation=&#39;relu&#39;))
model.add(Dense(114))
model.add(Dense(1))
adam = Adam(0.0001)
#Model compilation
model.compile(optimizer=adam, loss=&#39;mean_squared_error&#39;, metrics=[r2])
print(model.summary())
history = model.fit(x,y,epochs=150, batch_size=5, validation_split=0.2)
pd.DataFrame(model.history.history)[[&#39;r2&#39;,&#39;val_r2&#39;]].reset_index().plot(&#39;index&#39;, kind=&#39;line&#39;)
data = pd.DataFrame(history.history)
data.loc[data[&#39;r2&#39;].idxmax()]

2)ann
#CLASSIFICATION
#importing the necessary libraries
import numpy as np
import pandas as pd
#Importing data
data = pd.read_csv(&#39;/content/drive/MyDrive/Dataset/healthcare-dataset-stroke-data.csv&#39;)
data.head()
data=data.dropna()
data.columns
df=data[[&#39;age&#39;,&#39;hypertension&#39;,&#39;heart_disease&#39;,&#39;avg_glucose_level&#39;,&#39;bmi&#39;,&#39;stroke&#39;]]
df.head()
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df[&#39;gender&#39;] = le.fit_transform(data[&#39;gender&#39;])
df[&#39;ever_married&#39;] = le.fit_transform(data[&#39;ever_married&#39;])
df[&#39;work_type&#39;] = le.fit_transform(data[&#39;work_type&#39;])
df[&#39;Residence_type&#39;] = le.fit_transform(data[&#39;Residence_type&#39;])
df[&#39;smoking_status&#39;] = le.fit_transform(data[&#39;smoking_status&#39;])
df.head()
data.shape
df.shape

x = df.drop(&#39;stroke&#39;,axis=1)
y = df[&#39;stroke&#39;]
x.shape
y.shape
import seaborn as sns
import matplotlib.pyplot as plt
sns.countplot(df,x=&#39;stroke&#39;)
plt.xticks([0,1],[&#39;NO&#39;,&#39;YES&#39;])
plt.title(&#39;COUNT PLOT&#39;)
from sklearn.model_selection import train_test_split as tts
x_train, x_test, y_train, y_test= tts(x,y,test_size=0.2)
#Model creation and compilation
import tensorflow as tf
from tensorflow.keras.layers import Dense
ann = tf.keras.Sequential()
ann.add(Dense(units=25, activation=&#39;relu&#39;))
ann.add(Dense(units=25,activation=&#39;relu&#39;))
ann.add(Dense(units=1,activation=&#39;sigmoid&#39;))
ann.compile(&#39;adam&#39;,&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])
result = ann.fit(x_train,y_train,epochs=10)
y_pred=[]
for i in ann.predict(x_test):
if i&gt;0.5:
y_pred.append(1)
if i&lt;0.5:
y_pred.append(0)
from sklearn.metrics import confusion_matrix
confusion_matrix(y_test,y_pred)
from sklearn.metrics import accuracy_score
accuracy=accuracy_score(y_test,y_pred)
accuracy

#Regression
#Importing necessary libraries
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras import Sequential
df = pd.read_csv(&#39;/content/drive/MyDrive/Dataset/CarPrice_Assignment (1).csv&#39;)
df
df.columns
df = pd.get_dummies(df)
df.head()
x = df.drop([&#39;price&#39;],axis=1)
y = df.price
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3)
x_train.shape
from keras import backend as k
def r2(y_true,y_pred):
ss_res = k.sum(k.square(y_true-y_pred))
ss_tot = k.sum(k.square(y_true-k.mean(y_true)))
return (1-ss_res/(ss_tot))
model = Sequential()
model.add(Dense(400,activation=&#39;relu&#39;,input_dim=198))
model.add(Dense(240,activation=&#39;relu&#39;))
model.add(Dense(1))

model.compile(optimizer=&#39;Adam&#39;,loss=&#39;mean_absolute_error&#39;,metrics=[r2])
hist = model.fit(x_train,y_train,epochs=150, batch_size=5, validation_split=0.3)
pd.DataFrame(model.history.history).reset_index().plot(&#39;index&#39;,kind=&#39;line&#39;)
pd.DataFrame(model.history.history)[[&#39;r2&#39;,&#39;val_r2&#39;]].reset_index().plot(&#39;index&#39;, kind=&#39;line&#39;)
data = pd.DataFrame(hist.history)
data.loc[data[&#39;r2&#39;].idxmax()]

3)CNN Mnist
#Classification
#Importing the libraries
import numpy as np
import tensorflow as tf
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
import warnings
warnings.filterwarnings(&#39;ignore&#39;)
#Initializing the values
batch_size = 128
num_classes = 10
epochs = 2
#Loading and splitting the data
(x_train,y_train),(x_test,y_test) = mnist.load_data()
x_train = x_train.reshape(60000,28,28,1)
x_test = x_test.reshape(10000,28,28,1)
x_train = x_train.astype(&#39;float32&#39;)
x_test = x_test.astype(&#39;float32&#39;)
#Normalize values 0 to 1
x_train/=255
x_test/=255
print(x_train.shape[0],&#39;train samples&#39;)
print(x_test.shape[0],&#39;test samples&#39;)
#Convert class vectors to binary class metrics
from tensorflow.keras.utils import to_categorical

y_train=to_categorical(y_train,num_classes)
y_test=to_categorical(y_test,num_classes)
#Viewing an image
import pylab as plt
print(&#39;label:&#39;,y_test[400:401])
plt.imshow(x_test[400:401].reshape(28,28),cmap=&#39;gray&#39;)
plt.show()
#Model creation
model=Sequential()
model.add(Conv2D(8,kernel_size=(3,3),activation=&#39;relu&#39;,input_shape=(28,28,1)))
model.add(Conv2D(filters=16,kernel_size=(3,3),activation=&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(32,activation=&#39;relu&#39;))
model.add(Dropout(0.5))
model.add(Dense(num_classes,activation=&#39;softmax&#39;))
model.summary()
#Model compilation
model.compile(loss = keras.losses.categorical_crossentropy, optimizer =
tf.keras.optimizers.Adam(), metrics = [&#39;accuracy&#39;])

model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, verbose = 1,
validation_data = (x_test,y_test))
#Model evaluation
score = model.evaluate(x_test,y_test, verbose = 0)
print(&#39;Test Loss: &#39;, score[0])
print(&#39;Test Accuracy: &#39;, score[1])
#Comparing the original image with predicted value
import pylab as plt
plt.imshow(x_test[230:231].reshape(28,28), cmap= &#39;gray&#39;)
plt.show()
import numpy as np

prediction = model.predict(x_test[230:231])
print(&#39;Prediction score:\n&#39;,prediction[0])
thresholded = (prediction &gt; 0.5) * 1
print(&#39;\nThresholded score:\n&#39;,thresholded[0])
print(&#39;Predicted digit:\n&#39;,np.where(thresholded == 1)[1][0])

4)Cnn for image
#Importing the libraries
import numpy as np
import tensorflow as tf
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from keras.datasets import cifar10
from keras.utils import to_categorical
import warnings
warnings.filterwarnings(&#39;ignore&#39;)
batch_size = 128
num_classes = 10
epochs = 20
#Importing data
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train = x_train.reshape(50000,32,32,3)
x_test = x_test.reshape(10000,32,32,3)
x_train = x_train.astype(&#39;float32&#39;)
x_test = x_test.astype(&#39;float32&#39;)
x_train/=255
x_test/=255
print(x_train.shape[0],&#39;train samples&#39;)

print(x_test.shape[0],&#39;test samples&#39;)
from tensorflow.keras.utils import to_categorical
y_train=to_categorical(y_train,num_classes)
y_test=to_categorical(y_test,num_classes)
import pylab as plt
print(&#39;label:&#39;,y_test[110])
plt.imshow(x_test[110].reshape(32,32,3))
plt.show()
model=Sequential()
model.add(Conv2D(8,kernel_size=(3,3),activation=&#39;relu&#39;,input_shape=(32,32,3)))
model.add(Conv2D(filters=16,kernel_size=(3,3),activation=&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(32,activation=&#39;relu&#39;))
model.add(Dropout(0.5))
model.add(Dense(num_classes,activation=&#39;softmax&#39;))
model.summary()
model.compile(loss = keras.losses.categorical_crossentropy, optimizer =
tf.keras.optimizers.Adam(), metrics = [&#39;accuracy&#39;])
model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, verbose = 1,
validation_data = (x_test,y_test))
score = model.evaluate(x_test,y_test, verbose = 0)
print(&#39;Test Loss: &#39;, score[0])
print(&#39;Test Accuracy: &#39;, score[1])
import pylab as plt
plt.imshow(x_test[200].reshape(32,32,3), cmap= &#39;gray&#39;)
plt.show()
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0
# Define the labels of the dataset
class_names = [&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;,
&#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]
#Visualization
plt.figure(figsize=(10,10))
for i in range(25):
plt.subplot(5,5,i+1)
plt.xticks([])
plt.yticks([])
plt.grid(False)
plt.imshow(train_images[i])
plt.xlabel(class_names[train_labels[i][0]])
plt.show()
#Model creation
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation=&#39;relu&#39;, input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation=&#39;relu&#39;))
model.summary()
model.add(layers.Flatten())
model.add(layers.Dense(64, activation=&#39;relu&#39;))
model.add(layers.Dense(10))
model.summary()
#Model compilation
model.compile(optimizer=&#39;adam&#39;,
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
metrics=[&#39;accuracy&#39;])

history = model.fit(train_images, train_labels, epochs=10,
validation_data=(test_images, test_labels))
#Visualize and evaluate
plt.plot(history.history[&#39;accuracy&#39;], label=&#39;accuracy&#39;)
plt.plot(history.history[&#39;val_accuracy&#39;], label = &#39;val_accuracy&#39;)
plt.xlabel(&#39;Epoch&#39;)
plt.ylabel(&#39;Accuracy&#39;)
plt.ylim([0.5, 1])
plt.legend(loc=&#39;lower right&#39;)
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=1)
print(test_acc)
print(test_loss)
